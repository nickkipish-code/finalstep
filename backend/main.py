"""
Virtual Fitting Room API - Gemini 2.5 Flash Image
Backend –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Google Gemini AI
"""

import io
import os
import logging
from typing import Optional
from dotenv import load_dotenv
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import google.generativeai as genai

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="Virtual Fitting Room API - Gemini 2.5 Flash Image",
    description="API –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–π –ø—Ä–∏–º–µ—Ä–∫–∏ –æ–¥–µ–∂–¥—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini 2.5 Flash Image",
    version="1.0.0"
)

# CORS –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    logger.warning("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")
else:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info("‚úÖ Gemini API –Ω–∞—Å—Ç—Ä–æ–µ–Ω")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
try:
    model = genai.GenerativeModel('gemini-2.5-flash-image')
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å gemini-2.5-flash-image –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    model = None


def add_watermark(image: Image.Image, text: str = "Virtual Fitting Room") -> Image.Image:
    """–î–æ–±–∞–≤–ª—è–µ—Ç watermark –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é"""
    from PIL import ImageDraw, ImageFont
    
    img = image.copy()
    draw = ImageDraw.Draw(img)
    
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–π —à—Ä–∏—Ñ—Ç
        font = ImageFont.truetype("arial.ttf", 20)
    except:
        font = ImageFont.load_default()
    
    # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–Ω–∏–∑—É —Å–ø—Ä–∞–≤–∞
    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]
    
    position = (img.width - text_width - 10, img.height - text_height - 10)
    draw.text(position, text, fill=(255, 255, 255, 180), font=font)
    
    return img


async def generate_with_gemini(
    person_image: Image.Image,
    clothing_description: Optional[str] = None,
    clothing_image: Optional[Image.Image] = None
) -> Image.Image:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –æ–¥–µ–∂–¥–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini 2.5 Flash Image
    
    Args:
        person_image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞
        clothing_description: –¢–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–¥–µ–∂–¥—ã
        clothing_image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–µ–∂–¥—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        PIL Image —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
    """
    if not model:
        raise HTTPException(status_code=500, detail="Gemini –º–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞ –≤ bytes
        img_byte_arr = io.BytesIO()
        person_image.save(img_byte_arr, format='PNG')
        person_bytes = img_byte_arr.getvalue()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ image_part –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞
        person_part = {
            'mime_type': 'image/png',
            'data': person_bytes
        }
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
        if clothing_description:
            prompt = f"""You are an expert AI virtual fitting room assistant.

Task: Transform this person's image to show them wearing: {clothing_description}

Requirements:
- Keep the person's face, body shape, pose, and proportions EXACTLY the same
- Add the described clothing naturally fitting their body
- Maintain realistic lighting, shadows, and fabric physics
- Keep the original background
- Ensure the clothing looks professional and realistic
- Match the style and colors from the description

Generate a photorealistic image showing the person wearing the described clothing."""
        else:
            prompt = """You are an expert AI virtual fitting room assistant.

Task: Transform this person's image to show them wearing the clothing from the provided image.

Requirements:
- Keep the person's face, body shape, pose, and proportions EXACTLY the same
- Transfer the clothing from the clothing image to the person naturally
- Maintain realistic lighting, shadows, and fabric physics
- Keep the original background
- Ensure the clothing looks professional and realistic
- Match the style and colors from the clothing image

Generate a photorealistic image showing the person wearing the clothing."""
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è Gemini
        content_parts = [person_part]
        
        if clothing_image:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–¥–µ–∂–¥—ã –≤ bytes
            clothing_byte_arr = io.BytesIO()
            clothing_image.save(clothing_byte_arr, format='PNG')
            clothing_bytes = clothing_byte_arr.getvalue()
            
            clothing_part = {
                'mime_type': 'image/png',
                'data': clothing_bytes
            }
            content_parts.append(clothing_part)
        
        content_parts.append(prompt)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini
        logger.info("üîÑ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini API...")
        response = model.generate_content(content_parts)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞
        if hasattr(response, 'parts'):
            for part in response.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    image_data = part.inline_data.data
                    result_image = Image.open(io.BytesIO(image_data))
                    logger.info("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ –æ—Ç Gemini")
                    return result_image
        
        # Fallback: –≤–æ–∑–≤—Ä–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ —Å watermark
        logger.warning("‚ö†Ô∏è Gemini –Ω–µ –≤–µ—Ä–Ω—É–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª —Å watermark")
        return add_watermark(person_image, "Original - No AI result")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        # Fallback: –≤–æ–∑–≤—Ä–∞—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ —Å watermark
        return add_watermark(person_image, f"Error: {str(e)[:30]}")


@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "message": "Virtual Fitting Room API",
        "status": "running",
        "engine": "Gemini 2.5 Flash Image",
        "model": "gemini-2.5-flash-image",
        "api_ready": model is not None
    }


@app.get("/health")
async def health():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return {
        "status": "healthy",
        "gemini_ready": model is not None,
        "model": "gemini-2.5-flash-image"
    }


@app.post("/api/try-on/text")
async def try_on_text(
    person_image: UploadFile = File(...),
    clothing_description: str = Form(...),
    strength: Optional[float] = Form(0.75)
):
    """
    Text to Image: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∫–∏ –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é
    
    Args:
        person_image: –§–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞
        clothing_description: –û–ø–∏—Å–∞–Ω–∏–µ –æ–¥–µ–∂–¥—ã
        strength: –°–∏–ª–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    
    Returns:
        PNG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    """
    try:
        # –ß—Ç–µ–Ω–∏–µ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞
        image_data = await person_image.read()
        person_img = Image.open(io.BytesIO(image_data))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if person_img.mode != 'RGB':
            person_img = person_img.convert('RGB')
        
        logger.info(f"üì∏ –ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞: {person_image.filename}")
        logger.info(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ –æ–¥–µ–∂–¥—ã: {clothing_description}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_image = await generate_with_gemini(
            person_image=person_img,
            clothing_description=clothing_description
        )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ PNG bytes
        output = io.BytesIO()
        result_image.save(output, format='PNG')
        output.seek(0)
        
        return StreamingResponse(
            io.BytesIO(output.read()),
            media_type="image/png",
            headers={"Content-Disposition": "inline; filename=result.png"}
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/try-on/image")
async def try_on_image(
    person_image: UploadFile = File(...),
    clothing_image: UploadFile = File(...),
    description: Optional[str] = Form(None),
    strength: Optional[float] = Form(0.75)
):
    """
    Image to Image: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∫–∏ –ø–æ —Ñ–æ—Ç–æ –æ–¥–µ–∂–¥—ã
    
    Args:
        person_image: –§–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞
        clothing_image: –§–æ—Ç–æ –æ–¥–µ–∂–¥—ã
        description: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        strength: –°–∏–ª–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    
    Returns:
        PNG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    """
    try:
        # –ß—Ç–µ–Ω–∏–µ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞
        person_data = await person_image.read()
        person_img = Image.open(io.BytesIO(person_data))
        
        # –ß—Ç–µ–Ω–∏–µ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–¥–µ–∂–¥—ã
        clothing_data = await clothing_image.read()
        clothing_img = Image.open(io.BytesIO(clothing_data))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if person_img.mode != 'RGB':
            person_img = person_img.convert('RGB')
        if clothing_img.mode != 'RGB':
            clothing_img = clothing_img.convert('RGB')
        
        logger.info(f"üì∏ –ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞: {person_image.filename}")
        logger.info(f"üëî –ü–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–µ–∂–¥—ã: {clothing_image.filename}")
        if description:
            logger.info(f"üìù –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ: {description}")
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è
        clothing_description = description if description else "the clothing from the provided image"
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result_image = await generate_with_gemini(
            person_image=person_img,
            clothing_description=clothing_description,
            clothing_image=clothing_img
        )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ PNG bytes
        output = io.BytesIO()
        result_image.save(output, format='PNG')
        output.seek(0)
        
        return StreamingResponse(
            io.BytesIO(output.read()),
            media_type="image/png",
            headers={"Content-Disposition": "inline; filename=result.png"}
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

